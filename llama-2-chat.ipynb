{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af3794b",
   "metadata": {},
   "source": [
    " # Llama 2 on AWS\n",
    " # Repository : https://github.com/tsaol/llama2-on-aws\n",
    " # Auther : Cao Liu\n",
    " # Date.  : July 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d458cf0-02e2-4066-927b-25fa5ef2a07e",
   "metadata": {},
   "source": [
    "***\n",
    "- `meta-textgeneration-llama-2-7b`\n",
    "- `meta-textgeneration-llama-2-13b`\n",
    "- `meta-textgeneration-llama-2-70b`\n",
    "- `meta-textgeneration-llama-2-7b-f`\n",
    "- `meta-textgeneration-llama-2-13b-f`\n",
    "- `meta-textgeneration-llama-2-70b-f`\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014424a8-7f8f-46a7-8963-2c3d454878b8",
   "metadata": {
    "jumpStartAlterations": [
     "modelIdVersion"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    model_id,\n",
    "    model_version,\n",
    ") = (\n",
    "    \"meta-textgeneration-llama-2-7b-f\",\n",
    "    \"*\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eef0dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52afae-868d-4736-881f-7180f393003a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#deploy the model \n",
    "\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "instance_type = 'ml.g5.2xlarge' \n",
    "model = JumpStartModel(model_id=model_id)\n",
    "predictor = model.deploy(instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40d2cd-e865-4732-b18e-dff3955b575d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "# Replace with your instance endpoint name\n",
    "endpoint_name = \"meta-textgeneration-llama-2-7b-f-2023-08-02-07-44-13-153\"\n",
    "\n",
    "# Initialize the SageMaker predictor\n",
    "sess = sagemaker.Session()\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),  # Use JSON format for input\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),  # Use JSON format for output\n",
    ")\n",
    "\n",
    "print(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6c57bb-2021-449d-8188-396d0ab9957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TestCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5adf9b4-c7e1-4090-aefe-9cae0d096968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_dialog(payload, response):\n",
    "    dialog = payload[\"inputs\"][0]\n",
    "    for msg in dialog:\n",
    "        print(f\"{msg['role'].capitalize()}: {msg['content']}\\n\")\n",
    "    print(\n",
    "        f\"> {response[0]['generation']['role'].capitalize()}: {response[0]['generation']['content']}\"\n",
    "    )\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183304da-3318-4534-b0e0-80d34a475b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"what is the recipe of mayonnaise?\"},\n",
    "        ]\n",
    "    ],\n",
    "    \"parameters\": {\"max_new_tokens\": 512, \"top_p\": 0.9, \"temperature\": 0.6},\n",
    "}\n",
    "try:\n",
    "    response = predictor.predict(payload, custom_attributes=\"accept_eula=true\")\n",
    "    print_dialog(payload, response)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dda8502-3078-44d1-8d13-bccf19707bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install gradio  --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f2cca-d045-489d-b13e-60254ecd3c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install typing-extensions --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61648d0b-de1b-4066-897b-b6f2951ba515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for llm\n",
    "parameters = {\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\":0.9,\n",
    "    \"max_new_tokens\": 256\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e96f0a0-89c6-4dce-9bb5-dcf3e7bd6716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## source\n",
    "import gradio as gr\n",
    "\n",
    "def history_to_dialog_format(chat_history: list[str]):\n",
    "    dialog = []\n",
    "    if len(chat_history) > 0:\n",
    "        for idx, message in enumerate(chat_history[0]):\n",
    "            role = \"user\" if idx % 2 == 0 else \"assistant\"\n",
    "            dialog.append({\n",
    "                \"role\": role,\n",
    "                \"content\": message,\n",
    "            })\n",
    "    return dialog\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Llama2 assistant\")\n",
    "    with gr.Column():\n",
    "        chatbot = gr.Chatbot()\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                message = gr.Textbox(label=\"Chat Message Box\", placeholder=\"Chat Message Box\", show_label=False)\n",
    "            with gr.Column():\n",
    "                with gr.Row():\n",
    "                    submit = gr.Button(\"Submit\")\n",
    "\n",
    "    def respond(message, chat_history):\n",
    "        dialog = history_to_dialog_format(chat_history)\n",
    "        dialog.append({\"role\": \"user\", \"content\": message})\n",
    "        prompt = message\n",
    "        # send request to endpoint\n",
    "        llm_response = predictor.predict({\"inputs\": [dialog], \"parameters\": parameters}, \n",
    "                                         custom_attributes=\"accept_eula=true\")\n",
    "        print(llm_response[0])\n",
    "        parsed_response = llm_response[-1]['generation']['content']\n",
    "        chat_history.append((message, parsed_response))\n",
    "        return \"\", chat_history\n",
    "\n",
    "    submit.click(respond, [message, chatbot], [message, chatbot], queue=False)\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e062d29",
   "metadata": {},
   "source": [
    "## Clean up the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cc5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd478e-a664-4c71-9ec1-ca7df57c7130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
